{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# üê£ Please follow me for new updates https://twitter.com/camenduru\n# üî• Please join our discord server https://discord.gg/k5BwmmvJJU\n# ü•≥ Please join my patreon community https://patreon.com/camenduru\n\n%cd /kaggle/working\n!wget https://github.com/camenduru/DemoFusion/raw/dev/pipeline_demofusion_sdxl.py -O /kaggle/working/pipeline_demofusion_sdxl.py\n\n!pip install -q diffusers accelerate gradio gradio_imageslider pyngrok\n\nimport gradio as gr\nfrom pipeline_demofusion_sdxl import DemoFusionSDXLPipeline\nfrom gradio_imageslider import ImageSlider\nimport torch, gc\n\ndef generate_images(prompt, negative_prompt, height, width, num_inference_steps, guidance_scale, cosine_scale_1, cosine_scale_2, cosine_scale_3, sigma, view_batch_size, stride, seed):\n    model_ckpt = \"camenduru/DemoFusion\"\n    pipe = DemoFusionSDXLPipeline.from_pretrained(model_ckpt, torch_dtype=torch.float16)\n    pipe = pipe.to(\"cuda\")\n    generator = torch.Generator(device='cuda')\n    generator = generator.manual_seed(int(seed))\n    images = pipe(prompt, negative_prompt=negative_prompt, generator=generator,\n                  height=int(height), width=int(width), view_batch_size=int(view_batch_size), stride=int(stride),\n                  num_inference_steps=int(num_inference_steps), guidance_scale=guidance_scale,\n                  cosine_scale_1=cosine_scale_1, cosine_scale_2=cosine_scale_2, cosine_scale_3=cosine_scale_3, sigma=sigma,\n                  multi_decoder=True, show_image=False, lowvram=True\n                 )\n    for i, image in enumerate(images):\n      image.save('image_'+str(i)+'.png')\n    pipe = None\n    gc.collect()\n    torch.cuda.empty_cache()\n    return (images[0], images[-1])\n\nwith gr.Blocks(title=f\"DemoFusion\") as demo:\n    with gr.Column():\n      with gr.Row():\n        with gr.Group():\n          prompt = gr.Textbox(label=\"Prompt\", value=\"Envision a portrait of an elderly woman, her face a canvas of time, framed by a headscarf with muted tones of rust and cream. Her eyes, blue like faded denim. Her attire, simple yet dignified.\")\n          negative_prompt = gr.Textbox(label=\"Negative Prompt\", value=\"blurry, ugly, duplicate, poorly drawn, deformed, mosaic\")\n          width = gr.Slider(minimum=1024, maximum=4096, step=1024, value=2048, label=\"Width\")\n          height = gr.Slider(minimum=1024, maximum=4096, step=1024, value=2048, label=\"Height\")\n          num_inference_steps = gr.Slider(minimum=10, maximum=100, step=1, value=50, label=\"Num Inference Steps\")\n          guidance_scale = gr.Slider(minimum=1, maximum=20, step=0.1, value=7.5, label=\"Guidance Scale\")\n          cosine_scale_1 = gr.Slider(minimum=0, maximum=5, step=0.1, value=3, label=\"Cosine Scale 1\")\n          cosine_scale_2 = gr.Slider(minimum=0, maximum=5, step=0.1, value=1, label=\"Cosine Scale 2\")\n          cosine_scale_3 = gr.Slider(minimum=0, maximum=5, step=0.1, value=1, label=\"Cosine Scale 3\")\n          sigma = gr.Slider(minimum=0.1, maximum=1, step=0.1, value=0.8, label=\"Sigma\")\n          view_batch_size = gr.Slider(minimum=4, maximum=32, step=4, value=4, label=\"View Batch Size\")\n          stride = gr.Slider(minimum=8, maximum=96, step=8, value=64, label=\"Stride\")\n          seed = gr.Number(label=\"Seed\", value=2013)\n          button = gr.Button()\n        output_images = ImageSlider(show_label=False)\n    button.click(fn=generate_images, inputs=[prompt, negative_prompt, height, width, num_inference_steps, guidance_scale, cosine_scale_1, cosine_scale_2, cosine_scale_3, sigma, view_batch_size, stride, seed], outputs=[output_images], show_progress=True)\n\nfrom pyngrok import ngrok, conf\nconf.get_default().auth_token = \"NGROK_TOKEN_HERE\"\npublic_url = ngrok.connect(7860).public_url\nprint(public_url)\n\ndemo.queue().launch(inline=False, share=False, debug=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}